Using cpu device
Wrapping the env in a DummyVecEnv.
Logging to runs/98gwhiyi/PPO_1
[2K-----------------------------━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1,713/10,000,000 [0m [ [33m0:00:00[0m < [36m0:59:59[0m , [31m2,778 it/s[0m ]
| time/              |      |
|    fps             | 2676 |
|    iterations      | 1    |
|    time_elapsed    | 0    |
|    total_timesteps | 2048 |
-----------------------------
[2K-----------------------------------------━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m4,074/10,000,000 [0m [ [33m0:00:02[0m < [36m1:46:59[0m , [31m1,557 it/s[0m ]
| time/                   |             |
|    fps                  | 1585        |
|    iterations           | 2           |
|    time_elapsed         | 2           |
|    total_timesteps      | 4096        |
| train/                  |             |
|    approx_kl            | 0.015801165 |
|    clip_fraction        | 0.144       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.26       |
|    explained_variance   | -0.0104     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.6e+04     |
|    n_updates            | 10          |
|    policy_gradient_loss | 0.000858    |
|    std                  | 1           |
|    value_loss           | 5.25e+04    |
-----------------------------------------
[2K--------------------------------------━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m5,972/10,000,000 [0m [ [33m0:00:04[0m < [36m2:03:37[0m , [31m1,348 it/s[0m ]
| time/                   |          |
|    fps                  | 1385     |
|    iterations           | 3        |
|    time_elapsed         | 4        |
|    total_timesteps      | 6144     |
| train/                  |          |
|    approx_kl            | 63.23123 |
|    clip_fraction        | 0.655    |
|    clip_range           | 0.2      |
|    entropy_loss         | -4.26    |
|    explained_variance   | -0.0439  |
|    learning_rate        | 0.0003   |
|    loss                 | 102      |
|    n_updates            | 20       |
|    policy_gradient_loss | 0.14     |
|    std                  | 1.01     |
|    value_loss           | 1.37e+04 |
--------------------------------------
[2K---------------------------------------━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m8,006/10,000,000 [0m [ [33m0:00:06[0m < [36m2:11:47[0m , [31m1,264 it/s[0m ]
| time/                   |           |
|    fps                  | 1282      |
|    iterations           | 4         |
|    time_elapsed         | 6         |
|    total_timesteps      | 8192      |
| train/                  |           |
|    approx_kl            | 119.13857 |
|    clip_fraction        | 0.845     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.28     |
|    explained_variance   | 0.554     |
|    learning_rate        | 0.0003    |
|    loss                 | 95.6      |
|    n_updates            | 30        |
|    policy_gradient_loss | 0.232     |
|    std                  | 1.01      |
|    value_loss           | 2.27e+03  |
---------------------------------------
[2K---------------------------------------━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m9,953/10,000,000 [0m [ [33m0:00:08[0m < [36m2:16:50[0m , [31m1,217 it/s[0m ]
| time/                   |           |
|    fps                  | 1250      |
|    iterations           | 5         |
|    time_elapsed         | 8         |
|    total_timesteps      | 10240     |
| train/                  |           |
|    approx_kl            | 43.800262 |
|    clip_fraction        | 0.912     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.28     |
|    explained_variance   | 0.72      |
|    learning_rate        | 0.0003    |
|    loss                 | 182       |
|    n_updates            | 40        |
|    policy_gradient_loss | 0.253     |
|    std                  | 1.01      |
|    value_loss           | 3.44e+03  |
---------------------------------------
[2K---------------------------------------━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m12,011/10,000,000 [0m [ [33m0:00:09[0m < [36m2:17:09[0m , [31m1,214 it/s[0m ]
| time/                   |           |
|    fps                  | 1238      |
|    iterations           | 6         |
|    time_elapsed         | 9         |
|    total_timesteps      | 12288     |
| train/                  |           |
|    approx_kl            | 124.44504 |
|    clip_fraction        | 0.899     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.29     |
|    explained_variance   | 0.323     |
|    learning_rate        | 0.0003    |
|    loss                 | 46.6      |
|    n_updates            | 50        |
|    policy_gradient_loss | 0.268     |
|    std                  | 1.01      |
|    value_loss           | 306       |
---------------------------------------
[2K---------------------------------------━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m14,171/10,000,000 [0m [ [33m0:00:11[0m < [36m2:15:51[0m , [31m1,225 it/s[0m ]
| time/                   |           |
|    fps                  | 1240      |
|    iterations           | 7         |
|    time_elapsed         | 11        |
|    total_timesteps      | 14336     |
| train/                  |           |
|    approx_kl            | 210.69894 |
|    clip_fraction        | 0.932     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.3      |
|    explained_variance   | 0.847     |
|    learning_rate        | 0.0003    |
|    loss                 | 228       |
|    n_updates            | 60        |
|    policy_gradient_loss | 0.278     |
|    std                  | 1.01      |
|    value_loss           | 548       |
---------------------------------------
[2K---------------------------------------━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m16,285/10,000,000 [0m [ [33m0:00:13[0m < [36m2:19:45[0m , [31m1,191 it/s[0m ]
| time/                   |           |
|    fps                  | 1200      |
|    iterations           | 8         |
|    time_elapsed         | 13        |
|    total_timesteps      | 16384     |
| train/                  |           |
|    approx_kl            | 55.874973 |
|    clip_fraction        | 0.955     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.31     |
|    explained_variance   | 0.91      |
|    learning_rate        | 0.0003    |
|    loss                 | 31.8      |
|    n_updates            | 70        |
|    policy_gradient_loss | 0.297     |
|    std                  | 1.02      |
|    value_loss           | 97.1      |
---------------------------------------
[2K---------------------------------------━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m18,247/10,000,000 [0m [ [33m0:00:15[0m < [36m2:22:27[0m , [31m1,168 it/s[0m ]
| time/                   |           |
|    fps                  | 1180      |
|    iterations           | 9         |
|    time_elapsed         | 15        |
|    total_timesteps      | 18432     |
| train/                  |           |
|    approx_kl            | 112.78896 |
|    clip_fraction        | 0.938     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.31     |
|    explained_variance   | 0.896     |
|    learning_rate        | 0.0003    |
|    loss                 | 103       |
|    n_updates            | 80        |
|    policy_gradient_loss | 0.265     |
|    std                  | 1.02      |
|    value_loss           | 624       |
---------------------------------------
[2KEval num_timesteps=20000, episode_reward=-283093.95 +/- 0.00━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m19,999/10,000,000 [0m [ [33m0:00:47[0m < [36m4:12:12[0m , [31m660 it/s[0m ]
[2KEpisode length: 19999.00 +/- 0.00━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m19,999/10,000,000 [0m [ [33m0:00:47[0m < [36m4:12:12[0m , [31m660 it/s[0m ]
[2K---------------------------------------━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m19,999/10,000,000 [0m [ [33m0:00:47[0m < [36m4:12:12[0m , [31m660 it/s[0m ]
| eval/                   |           |
|    mean_ep_length       | 2e+04     |
|    mean_reward          | -2.83e+05 |
| time/                   |           |
|    total_timesteps      | 20000     |
| train/                  |           |
|    approx_kl            | 133.17868 |
|    clip_fraction        | 0.96      |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.31     |
|    explained_variance   | 0.762     |
|    learning_rate        | 0.0003    |
|    loss                 | 127       |
|    n_updates            | 90        |
|    policy_gradient_loss | 0.313     |
|    std                  | 1.02      |
|    value_loss           | 327       |
---------------------------------------
[2KNew best mean reward!m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m19,999/10,000,000 [0m [ [33m0:00:47[0m < [36m4:12:12[0m , [31m660 it/s[0m ]
[2K----------------------------------━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m20,250/10,000,000 [0m [ [33m0:00:47[0m < [36m192:37:06[0m , [31m14 it/s[0m ]
| rollout/           |           |
|    ep_len_mean     | 2e+04     |
|    ep_rew_mean     | -2.57e+05 |
| time/              |           |
|    fps             | 430       |
|    iterations      | 10        |
|    time_elapsed    | 47        |
|    total_timesteps | 20480     |
----------------------------------
[2K---------------------------------------━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m22,400/10,000,000 [0m [ [33m0:00:49[0m < [36m21:53:23[0m , [31m127 it/s[0m ]
| rollout/                |           |
|    ep_len_mean          | 2e+04     |
|    ep_rew_mean          | -2.57e+05 |
| time/                   |           |
|    fps                  | 459       |
|    iterations           | 11        |
|    time_elapsed         | 49        |
|    total_timesteps      | 22528     |
| train/                  |           |
|    approx_kl            | 112.1972  |
|    clip_fraction        | 0.851     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.32     |
|    explained_variance   | 0.904     |
|    learning_rate        | 0.0003    |
|    loss                 | 2.34e+03  |
|    n_updates            | 100       |
|    policy_gradient_loss | 0.156     |
|    std                  | 1.02      |
|    value_loss           | 6.09e+03  |
---------------------------------------
[2K---------------------------------------━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m24,396/10,000,000 [0m [ [33m0:00:50[0m < [36m13:04:21[0m , [31m212 it/s[0m ]
| rollout/                |           |
|    ep_len_mean          | 2e+04     |
|    ep_rew_mean          | -2.57e+05 |
| time/                   |           |
|    fps                  | 483       |
|    iterations           | 12        |
|    time_elapsed         | 50        |
|    total_timesteps      | 24576     |
| train/                  |           |
|    approx_kl            | 150.53903 |
|    clip_fraction        | 0.889     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.32     |
|    explained_variance   | 0.873     |
|    learning_rate        | 0.0003    |
|    loss                 | 862       |
|    n_updates            | 110       |
|    policy_gradient_loss | 0.268     |
|    std                  | 1.02      |
|    value_loss           | 1.76e+03  |
---------------------------------------
[2K---------------------------------------━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m26,507/10,000,000 [0m [ [33m0:00:52[0m < [36m9:36:46[0m , [31m288 it/s[0m ]
| rollout/                |           |
|    ep_len_mean          | 2e+04     |
|    ep_rew_mean          | -2.57e+05 |
| time/                   |           |
|    fps                  | 505       |
|    iterations           | 13        |
|    time_elapsed         | 52        |
|    total_timesteps      | 26624     |
| train/                  |           |
|    approx_kl            | 30.96067  |
|    clip_fraction        | 0.965     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.31     |
|    explained_variance   | 0.612     |
|    learning_rate        | 0.0003    |
|    loss                 | 504       |
|    n_updates            | 120       |
|    policy_gradient_loss | 0.301     |
|    std                  | 1.02      |
|    value_loss           | 3.7e+03   |
---------------------------------------
[2KTraceback (most recent call last):━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m26,507/10,000,000 [0m [ [33m0:00:52[0m < [36m9:36:46[0m , [31m288 it/s[0m ]
[2K  File "/root/workspace/college-math/mxm/RL4DA_MXM/enkf_L63/scripts/train-on-the-go.py", line 165, in <module>━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m26,507/10,000,000 [0m [ [33m0:00:52[0m < [36m9:36:46[0m , [31m288 it/s[0m ]
    model.learn(
[2K  File "/root/miniconda3/envs/main/lib/python3.12/site-packages/stable_baselines3/ppo/ppo.py", line 311, in learn━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m26,507/10,000,000 [0m [ [33m0:00:52[0m < [36m9:36:46[0m , [31m288 it/s[0m ]
    return super().learn(
           ^^^^^^^^^^^^^^
[2K  File "/root/miniconda3/envs/main/lib/python3.12/site-packages/stable_baselines3/common/on_policy_algorithm.py", line 336, in learn━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m26,507/10,000,000 [0m [ [33m0:00:52[0m < [36m9:36:46[0m , [31m288 it/s[0m ]
    self.train()
[2K  File "/root/miniconda3/envs/main/lib/python3.12/site-packages/stable_baselines3/ppo/ppo.py", line 213, in train━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m26,507/10,000,000 [0m [ [33m0:00:52[0m < [36m9:36:46[0m , [31m288 it/s[0m ]
    values, log_prob, entropy = self.policy.evaluate_actions(rollout_data.observations, actions)
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2K  File "/root/miniconda3/envs/main/lib/python3.12/site-packages/stable_baselines3/common/policies.py", line 738, in evaluate_actions━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m26,507/10,000,000 [0m [ [33m0:00:52[0m < [36m9:36:46[0m , [31m288 it/s[0m ]
    log_prob = distribution.log_prob(actions)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2K  File "/root/miniconda3/envs/main/lib/python3.12/site-packages/stable_baselines3/common/distributions.py", line 176, in log_prob━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m26,507/10,000,000 [0m [ [33m0:00:52[0m < [36m9:36:46[0m , [31m288 it/s[0m ]
    return sum_independent_dims(log_prob)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2K  File "/root/miniconda3/envs/main/lib/python3.12/site-packages/stable_baselines3/common/distributions.py", line 119, in sum_independent_dims━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m26,507/10,000,000 [0m [ [33m0:00:52[0m < [36m9:36:46[0m , [31m288 it/s[0m ]
    tensor = tensor.sum(dim=1)
             ^^^^^^^^^^^^^^^^^
[2KKeyboardInterrupt;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m26,507/10,000,000 [0m [ [33m0:00:52[0m < [36m9:36:46[0m , [31m288 it/s[0m ]
[2K[35m   0%[0m [38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m26,507/10,000,000 [0m [ [33m0:00:53[0m < [36m9:36:46[0m , [31m288 it/s[0m ]
